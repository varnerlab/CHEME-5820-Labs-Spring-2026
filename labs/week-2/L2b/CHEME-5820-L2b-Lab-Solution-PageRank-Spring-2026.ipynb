{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a39ab0",
   "metadata": {},
   "source": [
    "# L2b: What does the largest eigenpair represent?\n",
    "Now that we know how to compute the largest eigenpair of a matrix, let's explore what these eigenvalues and eigenvectors represent. \n",
    "\n",
    "> __Learning Objectives:__\n",
    ">\n",
    "> By the end of this lab, you will be able to:\n",
    ">\n",
    "> * __Construct transition matrices from graph adjacency matrices:__ Convert edge lists into adjacency matrices and normalize them to create probability transition matrices for random walks.\n",
    "> * __Apply power iteration to find the largest eigenpair:__ Use the power iteration algorithm to compute the dominant eigenvalue and corresponding eigenvector of a transition matrix.\n",
    "> * __Interpret stationary distributions as PageRank scores:__ Explain how the eigenvector corresponding to the largest eigenvalue represents webpage importance in the PageRank algorithm.\n",
    "\n",
    "\n",
    "Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8264ce",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "First, we set up the computational environment by including the `Include.jl` file and loading any needed resources.\n",
    "\n",
    "> The [`include(...)` command](https://docs.julialang.org/en/v1/base/base/#include) evaluates the contents of the input source file, `Include.jl`, in the notebook's global scope. The `Include.jl` file sets paths, loads required external packages, etc. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). \n",
    "\n",
    "Let's set up our code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ab3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"Include.jl\")); # include the Include.jl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f1c5c",
   "metadata": {},
   "source": [
    "In addition to standard Julia libraries, we'll also use [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). Check out [the documentation](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/) for more information on the functions, types, and data used in this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111aa900",
   "metadata": {},
   "source": [
    "### Data\n",
    "Next, let's load up the dataset that we will explore. This dataset was generated with the help of generative AI and a simple randomized graph generator for teaching and demonstration purposes. \n",
    "\n",
    "It does not contain real hyperlinks, real traffic patterns, or data collected from any website. Any resemblance to real domains is coincidental (the domain-like labels are fabricated).\n",
    "\n",
    "We've provided [the `MySyntheticPageRankDataset()` function](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/data/#VLDataScienceMachineLearningPackage.MySyntheticPageRankDataset) to load the synthetic PageRank dataset. This function takes no arguments and returns a tuple containing the edges and nodes of the synthetic web graph.\n",
    "\n",
    "> __What's in the dataset?__\n",
    "> \n",
    "> The dataset contains two data structures: `edges::Dict{Int, Tuple{String, String}}` maps edge indices to pairs of node identifiers (from_node, to_node), representing directed hyperlinks between webpages. The `nodes::Dict{String, NamedTuple}` maps node identifiers to named tuples containing metadata such as page labels, community assignments, and page types.\n",
    "\n",
    "Let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2422d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(edges, nodes) = MySyntheticPageRankDataset(); # load the synthetic PageRank dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d90d70f",
   "metadata": {},
   "source": [
    "Let's take a look at the `edges::Dict{Int, Tuple{String, String}}` dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e40fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Tuple{String, String}} with 2564 entries:\n",
       "  1144 => (\"p0096\", \"p0104\")\n",
       "  2108 => (\"p0188\", \"p0170\")\n",
       "  1175 => (\"p0096\", \"p0219\")\n",
       "  1953 => (\"p0172\", \"p0142\")\n",
       "  719  => (\"p0065\", \"p0087\")\n",
       "  1546 => (\"p0129\", \"p0126\")\n",
       "  1703 => (\"p0143\", \"p0157\")\n",
       "  1956 => (\"p0172\", \"p0147\")\n",
       "  2261 => (\"p0197\", \"p0201\")\n",
       "  2288 => (\"p0200\", \"p0197\")\n",
       "  1028 => (\"p0089\", \"p0118\")\n",
       "  699  => (\"p0063\", \"p0073\")\n",
       "  831  => (\"p0075\", \"p0045\")\n",
       "  1299 => (\"p0108\", \"p0105\")\n",
       "  1438 => (\"p0119\", \"p0092\")\n",
       "  1074 => (\"p0093\", \"p0110\")\n",
       "  2350 => (\"p0205\", \"p0209\")\n",
       "  2493 => (\"p0221\", \"p0224\")\n",
       "  319  => (\"p0023\", \"p0000\")\n",
       "  ⋮    => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e9287",
   "metadata": {},
   "source": [
    "How about the `nodes::Dict{String, NamedTuple}` dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9dab04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, NamedTuple} with 242 entries:\n",
       "  \"p0020\" => (nodeid = \"p0020\", label = \"ledger-ne20.com\", community = \"news\", …\n",
       "  \"p0065\" => (nodeid = \"p0065\", label = \"review-sc20.net\", community = \"science…\n",
       "  \"p0229\" => (nodeid = \"p0229\", label = \"deal-09-clickbait.com\", community = \"s…\n",
       "  \"p0217\" => (nodeid = \"p0217\", label = \"pop-en42.io\", community = \"entertainme…\n",
       "  \"p0126\" => (nodeid = \"p0126\", label = \"sportsbook-sp36.io\", community = \"spor…\n",
       "  \"p0070\" => (nodeid = \"p0070\", label = \"journal-sc25.com\", community = \"scienc…\n",
       "  \"p0194\" => (nodeid = \"p0194\", label = \"reel-en19.io\", community = \"entertainm…\n",
       "  \"p0123\" => (nodeid = \"p0123\", label = \"locker-sp33.net\", community = \"sports\"…\n",
       "  \"p0156\" => (nodeid = \"p0156\", label = \"fund-fi26.io\", community = \"finance\", …\n",
       "  \"p0068\" => (nodeid = \"p0068\", label = \"lab-sc23.org\", community = \"science\", …\n",
       "  \"p0200\" => (nodeid = \"p0200\", label = \"reel-en25.org\", community = \"entertain…\n",
       "  \"p0022\" => (nodeid = \"p0022\", label = \"bulletin-ne22.net\", community = \"news\"…\n",
       "  \"p0161\" => (nodeid = \"p0161\", label = \"capital-fi31.net\", community = \"financ…\n",
       "  \"p0013\" => (nodeid = \"p0013\", label = \"gazette-ne13.com\", community = \"news\",…\n",
       "  \"p0196\" => (nodeid = \"p0196\", label = \"pop-en21.net\", community = \"entertainm…\n",
       "  \"p0213\" => (nodeid = \"p0213\", label = \"reel-en38.com\", community = \"entertain…\n",
       "  \"p0118\" => (nodeid = \"p0118\", label = \"locker-sp28.com\", community = \"sports\"…\n",
       "  \"p0035\" => (nodeid = \"p0035\", label = \"ledger-ne35.org\", community = \"news\", …\n",
       "  \"p0075\" => (nodeid = \"p0075\", label = \"insights-sc30.com\", community = \"scien…\n",
       "  ⋮       => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c52ac",
   "metadata": {},
   "source": [
    "Finally, let's compute a few things we'll need below, in particular the list of nodes and the number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27226b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, [\"p0000\", \"p0001\", \"p0002\", \"p0003\", \"p0004\", \"p0005\", \"p0006\", \"p0007\", \"p0008\", \"p0009\"  …  \"p0232\", \"p0233\", \"p0234\", \"p0235\", \"p0236\", \"p0237\", \"p0238\", \"p0239\", \"p0240\", \"p0241\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_nodes, list_of_nodes = let\n",
    "\n",
    "    # initialize -\n",
    "    nodeset = Set{String}();\n",
    "    number_of_edges = keys(edges) |> length;\n",
    "\n",
    "    # loop over edges to build the set of nodes. \n",
    "    # Trick: Take advantage of the fact that sets do not allow duplicates (nice!)\n",
    "    for i ∈ 1:number_of_edges\n",
    "        (from_node, to_node) = edges[i];\n",
    "        push!(nodeset, from_node);\n",
    "        push!(nodeset, to_node);\n",
    "    end\n",
    "\n",
    "    # Of course, we want a sorted array of nodes (not a set), so let's convert to an array and sort it.\n",
    "    list_of_nodes = nodeset |> collect |> sort;\n",
    "    number_of_nodes = length(list_of_nodes); # how many nodes are there?\n",
    "\n",
    "    (number_of_nodes, list_of_nodes); # return \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6044b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b6e94",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f6870",
   "metadata": {},
   "source": [
    "## Task 1: Compute the transition matrix\n",
    "In this task, we will compute the transition matrix for the synthetic web graph dataset. To do this, first lets's convert our edge list into an adjacency matrix. Then, we will compute the transition matrix from the adjacency matrix.\n",
    "\n",
    "> __What is an adjacency matrix?__\n",
    "> \n",
    "> An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph. Suppose our adjancey matrix is given by $\\mathbf{A}$. Then, the element $A_{ij}$ is non-zero if there is an edge from node $i$ to node $j$. In particular, for an unweighted graph, $A_{ij} = 1$ if there is an edge from node $i$ to node $j$, and $A_{ij} = 0$ otherwise.\n",
    "\n",
    "Let's build the adjacency matrix as a sparse matrix to save memory. A sparse matrix is a matrix in which most of the elements are zero. Storing only the non-zero elements can save significant memory and computational resources, especially for large matrices. \n",
    "\n",
    "Julia provides support for sparse matrices through its standard library module, [SparseArrays](https://docs.julialang.org/en/v1/stdlib/SparseArrays/#stdlib-sparse-arrays). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba4a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = let\n",
    "\n",
    "    # initialize -\n",
    "    A = spzeros(Int, number_of_nodes, number_of_nodes); # sparse adjacency matrix\n",
    "\n",
    "    # ok, loop over edges to populate the adjacency matrix\n",
    "    for (i, (from_node, to_node)) ∈ edges\n",
    "        from_index = findfirst(isequal(from_node), list_of_nodes);\n",
    "        to_index   = findfirst(isequal(to_node), list_of_nodes);\n",
    "        A[from_index, to_index] = 1; # unweighted graph\n",
    "    end\n",
    "    \n",
    "    A # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602d375a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242×242 SparseMatrixCSC{Int64, Int64} with 2564 stored entries:\n",
       "⎡⣵⡿⣿⣿⢸⣿⣽⡆⠠⠠⠄⠀⡀⡄⠀⠈⢠⣅⠄⠠⠠⠠⠄⠆⠀⠀⠀⠀⠀⠄⡄⢄⢄⠀⠤⠠⠆⠀⠀⠀⎤\n",
       "⎢⣿⣿⡯⡞⣿⡿⣿⡇⠀⠐⠀⢀⢒⠢⣅⠠⠀⠌⠌⠀⠀⢀⠐⡃⠐⠀⠀⠰⠀⡀⠀⠀⠄⠁⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⣷⣷⣶⣷⢼⣯⣶⣇⠄⢀⠄⠀⢠⠀⡠⠂⠠⠄⠈⠠⠀⠄⠄⠆⡐⠀⠀⠀⠀⠈⠠⠐⢀⠐⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠟⠿⠿⠾⢤⠿⠿⢃⣂⡀⣀⠄⣀⣀⣀⠐⠀⠀⠐⠀⠀⠄⠀⠀⠀⠀⠀⠀⠐⠀⠀⠀⠀⠀⠀⠄⠀⠀⡀⠀⎥\n",
       "⎢⠀⠑⡦⠀⠀⣁⠬⢱⣴⡯⣏⣵⣼⡧⡼⠀⠠⠀⠀⢀⠀⠀⠀⠀⠈⠠⠀⠀⠰⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⢘⠀⠡⠀⡁⠀⢸⣽⡯⣕⣫⣿⣯⣺⠀⠀⡀⠀⠀⠀⠀⡀⠠⠀⠀⠀⠀⠐⠀⢀⠀⠀⠀⠀⠂⠀⠀⠀⠀⎥\n",
       "⎢⠀⢐⠈⠂⠀⠈⠀⢸⣢⣽⣟⣻⢼⡿⣿⠀⠀⠅⠀⠀⠀⠐⠅⠀⠠⠀⠀⠠⠀⠂⠀⠀⠈⠀⠀⠄⠀⠀⠀⠀⎥\n",
       "⎢⡢⣿⠦⠁⢀⣗⢕⠞⠚⢞⢟⠻⢟⢻⢺⣧⢤⣶⣤⣴⣤⣶⠆⢤⡐⢤⣂⠄⠷⠄⢈⡤⣔⢀⣄⠄⡆⠄⠐⡀⎥\n",
       "⎢⠀⡐⠤⠔⠠⠡⠰⠀⠀⡀⠤⠁⠀⠄⡂⣿⣻⣿⣧⣿⡽⡓⠠⠃⠀⠄⠀⠀⠂⠀⠀⠀⠀⠀⠠⠀⠀⠀⠀⠀⎥\n",
       "⎢⠐⠄⠖⠐⠄⡃⡀⠀⠀⠆⡀⠀⢠⡄⢂⣿⣿⣿⣯⡾⣿⡇⠀⠀⠀⠄⠀⠀⠀⠀⠀⠀⠂⠁⠀⠀⡀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠢⠄⠀⠥⠰⠌⢀⠀⠀⠁⠀⡠⠀⠿⢼⡿⠏⠿⠿⢇⣀⣀⣁⣀⡀⢀⡀⠀⠠⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⡀⡆⠄⠈⠀⡅⠀⡀⠀⡊⢈⠈⠉⠁⣀⡀⠅⡄⠉⠈⡀⢘⣯⡿⣿⣏⡃⣿⣟⠀⠀⠀⠠⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⢈⡐⠀⠀⠂⠀⠁⠀⠔⡀⠀⠀⠂⠣⠂⠀⠀⠂⠀⠀⡀⢸⣿⣷⣿⣮⠏⢏⡢⠀⠁⠀⡀⠀⠂⠀⠀⠀⠀⠀⎥\n",
       "⎢⠈⠀⠀⡀⠀⠀⠀⠂⠀⠀⠀⠀⠀⠌⠀⡀⠀⠄⠀⢈⠀⢰⣟⣿⠿⣿⡤⠸⣁⠀⠀⢀⠀⠀⠈⠀⠀⠀⠀⠀⎥\n",
       "⎢⠁⢁⠉⠈⠁⠃⠈⢙⠐⠍⠀⠩⢈⠁⠉⠉⠊⠀⠀⠀⠡⠉⠋⠋⠉⠉⠋⠉⢩⡔⢴⢮⢤⠶⣪⣅⡇⠀⠁⠀⎥\n",
       "⎢⡅⢨⠀⠌⠤⠀⢄⠤⠄⠠⠤⠨⠀⠬⠀⠥⠀⠤⠤⠄⠀⠴⠤⠤⠁⠄⢄⢠⣼⣯⣾⣭⣾⣧⣿⣭⡇⠁⠀⠀⎥\n",
       "⎢⠀⡆⠀⠀⢀⠠⠀⢠⠀⠀⠀⠀⠀⠁⠄⠁⠀⠀⠄⠀⠢⠄⠀⠂⠀⠈⠀⠀⢬⡽⣽⢥⣼⠿⣿⡿⡇⠀⠀⠀⎥\n",
       "⎢⠁⠆⠠⠀⠂⠀⠄⠀⠀⠈⠀⠀⢀⠂⡈⠄⠀⠀⠀⠀⠂⢀⠀⠄⠐⠂⠁⠀⢘⣯⢻⣍⢭⣽⣿⡧⡇⠀⠀⠀⎥\n",
       "⎢⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠈⠈⠀⠈⠁⠀⠁⠼⣾⠗⡓⎥\n",
       "⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢵⠻⢑⠴⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec31d42",
   "metadata": {},
   "source": [
    "> __What is a transition matrix?__\n",
    "> \n",
    "> A transition matrix $\\mathbf{P}$ is a row-stochastic matrix where each entry $P_{ij}$ represents the probability of transitioning from state $i$ to state $j$ in a discrete-time Markov chain. For a web graph, $P_{ij}$ is the probability that a random surfer currently at webpage $i$ follows a link to webpage $j$. The transition matrix is constructed from the adjacency matrix $\\mathbf{A}$ by normalizing each row: if webpage $i$ has $k$ outgoing links, then $P_{ij} = A_{ij}/k$ for each connected page $j$. This ensures each row sums to one, $\\sum_{j=1}^{n}P_{ij} = 1$ for all $i$, making it a valid probability distribution. Webpages with no outgoing links (dangling nodes) are handled by distributing probability uniformly across all pages: $P_{ij} = 1/n$ for all $j$.\n",
    "\n",
    "Let's compute the transition matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1ffd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242×242 SparseMatrixCSC{Float64, Int64} with 4500 stored entries:\n",
       "⎡⣵⡿⣿⣿⢸⣿⣽⡆⠠⠠⠄⠀⡀⡄⠀⠈⢠⣅⠄⠠⠠⠠⠄⠆⠀⠀⠀⠀⠀⠄⡄⢄⢄⠀⠤⠠⠆⠀⠀⠀⎤\n",
       "⎢⣿⣿⡯⡞⣿⡿⣿⡇⠀⠐⠀⢀⢒⠢⣅⠠⠀⠌⠌⠀⠀⢀⠐⡃⠐⠀⠀⠰⠀⡀⠀⠀⠄⠁⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⣷⣷⣶⣷⢼⣯⣶⣇⠄⢀⠄⠀⢠⠀⡠⠂⠠⠄⠈⠠⠀⠄⠄⠆⡐⠀⠀⠀⠀⠈⠠⠐⢀⠐⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠟⠿⠿⠾⢤⠿⠿⢃⣂⡀⣀⠄⣀⣀⣀⠐⠀⠀⠐⠀⠀⠄⠀⠀⠀⠀⠀⠀⠐⠀⠀⠀⠀⠀⠀⠄⠀⠀⡀⠀⎥\n",
       "⎢⠀⠑⡦⠀⠀⣁⠬⢱⣴⡯⣏⣵⣼⡧⡼⠀⠠⠀⠀⢀⠀⠀⠀⠀⠈⠠⠀⠀⠰⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠉⢙⠉⠩⠉⡉⠉⢹⣽⡯⣝⣫⣿⣯⣻⠉⠉⡉⠉⠉⠉⠉⡉⠩⠉⠉⠉⠉⠙⠉⢉⠉⠉⠉⠉⠋⠉⠉⠉⠉⎥\n",
       "⎢⠀⢐⠈⠂⠀⠈⠀⢸⣢⣽⣟⣻⢼⡿⣿⠀⠀⠅⠀⠀⠀⠐⠅⠀⠠⠀⠀⠠⠀⠂⠀⠀⠈⠀⠀⠄⠀⠀⠀⠀⎥\n",
       "⎢⡢⣿⠦⠁⢀⣗⢕⠞⠚⢞⢟⠻⢟⢻⢺⣧⢤⣶⣤⣴⣤⣶⠆⢤⡐⢤⣂⠄⠷⠄⢈⡤⣔⢀⣄⠄⡆⠄⠐⡀⎥\n",
       "⎢⠉⡙⠭⠝⠩⠩⠹⠉⠉⡉⠭⠉⠉⠍⡋⣿⣻⣿⣯⣿⡽⡛⠩⠋⠉⠍⠉⠉⠋⠉⠉⠉⠉⠉⠩⠉⠉⠉⠉⠉⎥\n",
       "⎢⠴⠤⠶⠴⠤⡧⡤⠤⠤⠦⡤⠤⢤⡤⢦⣿⣿⣿⣯⡾⣿⡧⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠦⠥⠤⠤⡤⠤⠤⠤⎥\n",
       "⎢⠀⠀⠢⠄⠀⠥⠰⠌⢀⠀⠀⠁⠀⡠⠀⠿⢼⡿⠏⠿⠿⢇⣀⣀⣁⣀⡀⢀⡀⠀⠠⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⡀⡆⠄⠈⠀⡅⠀⡀⠀⡊⢈⠈⠉⠁⣀⡀⠅⡄⠉⠈⡀⢘⣯⡿⣿⣏⡃⣿⣟⠀⠀⠀⠠⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⣈⣐⣀⣀⣂⣀⣁⣀⣔⣀⣀⣀⣂⣣⣂⣀⣀⣂⣀⣀⣀⣸⣿⣷⣿⣮⣏⣏⣢⣀⣁⣀⣀⣀⣂⣀⣀⣀⣀⣀⎥\n",
       "⎢⠾⠶⠶⡶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠾⠶⡶⠶⠶⠶⢾⠶⢶⣿⣿⠿⣿⡶⠾⣷⠶⠶⢶⠶⠶⠾⠶⠶⠶⠶⠶⎥\n",
       "⎢⠁⢁⠉⠈⠁⠃⠈⢙⠐⠍⠀⠩⢈⠁⠉⠉⠊⠀⠀⠀⠡⠉⠋⠋⠉⠉⠋⠉⢩⡔⢴⢮⢤⠶⣪⣅⡇⠀⠁⠀⎥\n",
       "⎢⡅⢨⠀⠌⠤⠀⢄⠤⠄⠠⠤⠨⠀⠬⠀⠥⠀⠤⠤⠄⠀⠴⠤⠤⠁⠄⢄⢠⣼⣯⣾⣭⣾⣧⣿⣭⡇⠁⠀⠀⎥\n",
       "⎢⠉⡏⠉⠉⢉⠩⠉⢩⠉⠉⠉⠉⠉⠉⠍⠉⠉⠉⠍⠉⠫⠍⠉⠋⠉⠉⠉⠉⢭⡽⣽⢭⣽⠿⣿⡿⡏⠉⠉⠉⎥\n",
       "⎢⠓⠖⠲⠒⠒⠒⠖⠒⠒⠚⠒⠒⢒⠒⡚⠖⠒⠒⠒⠒⠒⢒⠒⠖⠒⠒⠓⠒⢚⣿⢻⣟⢿⣿⣿⡷⡗⠒⠒⠒⎥\n",
       "⎢⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠈⠈⠀⠈⠁⠀⠁⠼⣾⠗⡓⎥\n",
       "⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢵⠻⢑⠴⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = let\n",
    "\n",
    "    # initialize -\n",
    "    P = spzeros(Float64, number_of_nodes, number_of_nodes); # sparse transition matrix\n",
    "\n",
    "    # loop over rows of A to compute the transition matrix\n",
    "    for i ∈ 1:number_of_nodes\n",
    "        row_sum = sum(A[i, :]); # sum of the i-th row\n",
    "        if row_sum != 0\n",
    "            P[i, :] .= A[i, :] ./ row_sum; # normalize the row (fancy! what is .= doing here?)\n",
    "        else\n",
    "            P[i, :] .= 1.0 / number_of_nodes; # handle dangling nodes (no outgoing edges)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    P # return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f2cf0",
   "metadata": {},
   "source": [
    "__Check__: If this is correct, then each row of the transition matrix should sum to one. You can verify this by summing the rows of the transition matrix and checking if they equal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "640bc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "\n",
    "    # initialize -\n",
    "    number_of_nodes = size(P, 1);\n",
    "\n",
    "    for i ∈ 1:number_of_nodes\n",
    "        row_sum = sum(P[i, :]);\n",
    "        @assert isapprox(row_sum, 1.0; atol=1e-8) \"Row $i does not sum to 1, sum = $row_sum\";\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a22f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242-element SparseVector{Float64, Int64} with 12 stored entries:\n",
       "  [7 ]  =  0.0833333\n",
       "  [11]  =  0.0833333\n",
       "  [13]  =  0.0833333\n",
       "  [16]  =  0.0833333\n",
       "  [19]  =  0.0833333\n",
       "  [20]  =  0.0833333\n",
       "  [27]  =  0.0833333\n",
       "  [30]  =  0.0833333\n",
       "  [31]  =  0.0833333\n",
       "  [37]  =  0.0833333\n",
       "  [40]  =  0.0833333\n",
       "  [96]  =  0.0833333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d8bd0",
   "metadata": {},
   "source": [
    "## Task 2: Compute the largest eigenpair of the transition matrix\n",
    "In this task, we will compute the largest eigenpair of the transition matrix $\\mathbf{P}$ using the power iteration method.\n",
    "\n",
    "> __Connection to Markov Processes:__\n",
    "\n",
    "> The algorithm iterates until the change in the eigenvector estimate (measured by the $\\ell_{1}$-norm) falls below a tolerance of $\\epsilon = 10^{-8}$. Let's run the power iteration:\n",
    "\n",
    "> The transition matrix $\\mathbf{P}$ defines a discrete-time Markov chain on the web graph. A central question in Markov theory is whether a stationary distribution exists: a probability vector $\\boldsymbol{\\pi}$ such that $\\boldsymbol{\\pi}^{\\top}\\mathbf{P} = \\boldsymbol{\\pi}^{\\top}$, meaning the distribution remains unchanged after one step of the random walk. Transposing both sides gives the eigenvalue equation $\\mathbf{P}^{\\top}\\boldsymbol{\\pi} = \\boldsymbol{\\pi}$, showing that $\\boldsymbol{\\pi}$ is an eigenvector of $\\mathbf{P}^{\\top}$ with eigenvalue $\\lambda = 1$. The Perron-Frobenius theorem for stochastic matrices guarantees that $\\lambda = 1$ is the largest eigenvalue (in magnitude), and for an irreducible, aperiodic chain, the corresponding eigenvector has all positive entries and is unique up to scalar multiplication. This eigenvector, when normalized to sum to one, is the unique stationary distribution representing the long-run fraction of time a random surfer spends at each webpage.\n",
    "\n",
    "> For a matrix $\\mathbf{P}$, we distinguish between right eigenvectors satisfying $\\mathbf{P}\\mathbf{v} = \\lambda\\mathbf{v}$ and left eigenvectors satisfying $\\mathbf{v}^{\\top}\\mathbf{P} = \\lambda\\mathbf{v}^{\\top}$. The left eigenvector equation can be rewritten as $\\mathbf{P}^{\\top}\\mathbf{v} = \\lambda\\mathbf{v}$ by transposing both sides. The stationary distribution is a left eigenvector because it satisfies $\\boldsymbol{\\pi}^{\\top}\\mathbf{P} = \\boldsymbol{\\pi}^{\\top}$, describing a distribution that is invariant under the transition dynamics. To compute it using power iteration (which finds right eigenvectors), we transpose $\\mathbf{P}$ and solve $\\mathbf{P}^{\\top}\\mathbf{v} = \\mathbf{v}$.\n",
    "\n",
    "> __Left versus Right Eigenvectors:__>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63051498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 31 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0000068472367856, [0.13134465564342657, 0.012992025847351435, 0.10260533053108949, 0.011474520931163572, 0.11173862780887117, 0.0625575224662041, 0.26319225632996196, 0.07035109197700304, 0.10734016447518378, 0.03470895403789316  …  0.009950263999003393, 0.006460825333222089, 0.002040729726507196, 0.0020828320290642117, 0.003242097434038535, 0.0017067363452438707, 0.0021996023434866525, 0.0027607235707679824, 0.0029599354447284675, 0.002434414531399812])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "λ̂,v̂ = let\n",
    "\n",
    "    # initialize -\n",
    "    max_iterations = 1000;\n",
    "    tolerance      = 1e-8;\n",
    "    v = rand(number_of_nodes); # random initial eigenvector\n",
    "    v .= v ./ norm(v, 1);      # normalize\n",
    "    A = transpose(P) |> Matrix;  # we want the left eigenvector, so we work with the transpose\n",
    "\n",
    "    # call the power iteration method\n",
    "    result = poweriteration(A, v; maxiter = max_iterations, ϵ = tolerance);\n",
    "\n",
    "    (result.value, result.vector) # return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b4a6c",
   "metadata": {},
   "source": [
    "What is the largest eigenvalue and corresponding eigenvector of the transition matrix $\\mathbf{P}$? Theory tells us that $\\hat{λ} = 1$ should be the largest eigenvalue of a transition matrix. Let's see if our computation agrees with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5364f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert isapprox(λ̂, 1.0; atol=1e-4) # adjust atol to find the max permissible error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f1000",
   "metadata": {},
   "source": [
    "> __Why normalize the eigenvector?__\n",
    "> \n",
    "> The power iteration returns an eigenvector $\\hat{\\mathbf{v}}$ satisfying $\\mathbf{P}^{\\top}\\hat{\\mathbf{v}} = \\hat{\\mathbf{v}}$, but eigenvectors are only defined up to scalar multiplication: if $\\mathbf{v}$ is an eigenvector, so is $c\\mathbf{v}$ for any nonzero scalar $c$. The power iteration algorithm normalizes at each step using the $\\ell_{1}$-norm to prevent numerical overflow, but the final vector is not necessarily a probability distribution. To interpret $\\hat{\\mathbf{v}}$ as a stationary distribution, we require $\\sum_{i=1}^{n}\\pi_{i} = 1$ so that $\\pi_{i}$ represents the fraction of time spent at node $i$. The normalization $\\hat{\\pi} = \\hat{\\mathbf{v}}/(\\mathbf{1}^{\\top}\\hat{\\mathbf{v}})$ where $\\mathbf{1}$ is a vector of ones ensures this property while preserving the relative magnitudes that encode webpage importance.\n",
    "\n",
    "Let's compute the stationary distribution:\n",
    "\n",
    "$$$$\n",
    "\\hat{\\pi} = \\frac{\\hat{\\mathbf{v}}}{\\mathbf{1}^{\\top} \\hat{\\mathbf{v}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f830dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242-element Vector{Float64}:\n",
       " 0.011599808148978161\n",
       " 0.0011474011375458993\n",
       " 0.009061671701772784\n",
       " 0.0010133814790628146\n",
       " 0.00986828614429315\n",
       " 0.005524817552176328\n",
       " 0.023244034291067365\n",
       " 0.006213112867110352\n",
       " 0.009479832342567095\n",
       " 0.003065348992838228\n",
       " ⋮\n",
       " 0.0005705929486228387\n",
       " 0.0001802286754298165\n",
       " 0.0001839469739011107\n",
       " 0.0002863284238776985\n",
       " 0.00015073178325172214\n",
       " 0.00019425963746675585\n",
       " 0.00024381550673983007\n",
       " 0.0002614090624701328\n",
       " 0.00021499726335256992"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "π̂ = let\n",
    "    \n",
    "    # initialize -\n",
    "    ones_vector = ones(number_of_nodes);\n",
    "    T = dot(ones_vector, v̂); # normalization factor\n",
    "    π̂  = v̂ ./ T # return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c794248d",
   "metadata": {},
   "source": [
    "__Check__: The entries of the stationary distribution $\\hat{\\pi}$ should sum to one. You can verify this by summing the entries of $\\hat{\\pi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f5a5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert isapprox(sum(π̂), 1.0; atol=1e-8) # check that the entries sum to one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c57469",
   "metadata": {},
   "source": [
    "Ok, but what does this stationary distribution represent in the context of our web graph? \n",
    "\n",
    "> __PageRank and Stationary Distribution__\n",
    "> In the context of PageRank, the stationary distribution $\\hat{\\pi}$ represents the long-term behavior of a random surfer navigating the web graph. Each entry $\\hat{\\pi}_i$ in the stationary distribution corresponds to the probability of being at node (webpage) $i$ after a large number of steps in a random walk on the graph.\n",
    "\n",
    "Let's find the most important webpage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d17ba3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 142\n",
      "The most important webpage is: p0141 with PageRank score 0.02469991255749491\n"
     ]
    }
   ],
   "source": [
    "nodeid = let\n",
    "    i = argmax(π̂);\n",
    "    nodeid = list_of_nodes[i];\n",
    "    println(\"The most important webpage is: $(list_of_nodes[i]) with PageRank score $(π̂[i])\");\n",
    "    nodeid;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc6e27",
   "metadata": {},
   "source": [
    "That `nodeid::String` variable holds the identifier of the most important webpage according to the PageRank analysis. What does this correspond to in the original dataset? You can look it up in the `nodes` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0c66f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nodeid = \"p0141\", label = \"promo_cash_now.org\", community = \"finance\", type = \"spam_target\")\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(nodes[nodeid])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327d261",
   "metadata": {},
   "source": [
    "> __Interpreting PageRank Scores:__\n",
    "> \n",
    "> In the PageRank context, \"most important\" refers to the webpage with the highest score $\\pi_{i}$ in the stationary distribution. This score has a precise probabilistic interpretation: it is the fraction of time a random surfer spends at webpage $i$ in the long run, assuming they navigate by uniformly randomly following outgoing links. High PageRank scores indicate structural importance within the network topology. A page achieves high PageRank through one of two mechanisms: receiving many incoming links (high in-degree), or receiving links from other high-PageRank pages (recursive importance). This captures the intuition that important pages are those that many other important pages link to, creating a self-reinforcing notion of authority. Critically, PageRank measures link structure, not content quality or relevance. A page about an obscure topic could have high PageRank if it is well-connected, while a high-quality page might have low PageRank if it lacks incoming links. The algorithm also treats all outgoing links from a page equally, so a link from a page with one outgoing link carries more weight than a link from a page with many outgoing links. This explains why pages that are linked from focused, specialized sources can achieve higher PageRank than pages linked from general directories with hundreds of outbound links.\n",
    "\n",
    "Let's look at the details of the top $n$ most important webpages [using the `PrettyTables.jl` package](https://github.com/ronisbr/PrettyTables.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd425f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- -------- -------------------- ------------------- ------------------- ---------------\n",
      " \u001b[1m  Rank \u001b[0m \u001b[1m NodeID \u001b[0m \u001b[1m           PageName \u001b[0m \u001b[1m         Community \u001b[0m \u001b[1m              Type \u001b[0m \u001b[1m PageRankScore \u001b[0m\n",
      " \u001b[90m Int64 \u001b[0m \u001b[90m String \u001b[0m \u001b[90m  SubString{String} \u001b[0m \u001b[90m SubString{String} \u001b[0m \u001b[90m SubString{String} \u001b[0m \u001b[90m       Float64 \u001b[0m\n",
      " ------- -------- -------------------- ------------------- ------------------- ---------------\n",
      "      1    p0141   promo_cash_now.org             finance         spam_target       0.0246999\n",
      "      2    p0006      gazette-ne06.io                news              portal        0.023244\n",
      "      3    p0030    bulletin-ne30.org                news           authority       0.0171696\n",
      "      4    p0130        fund-fi00.net             finance           authority       0.0144213\n",
      "      5    p0015       daily-ne15.net                news                 hub       0.0136233\n",
      "      6    p0175         pop-en00.net       entertainment           authority        0.013244\n",
      "      7    p0078    insights-sc33.org             science              normal       0.0127741\n",
      "      8    p0041    bulletin-ne41.org                news              normal       0.0120777\n",
      "      9    p0077     notebook-sc32.io             science              normal       0.0118493\n",
      "     10    p0151       alpha-fi21.org             finance              normal       0.0118188\n",
      " ------- -------- -------------------- ------------------- ------------------- ---------------\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    # initialize\n",
    "    number_of_sites_to_display = 10;\n",
    "    i = sortperm(π̂; rev=true)[1:number_of_sites_to_display] # indices of the top 10 most important webpages\n",
    "    df = DataFrame(); # hold the data for the table\n",
    "\n",
    "    for j ∈ 1:number_of_sites_to_display\n",
    "        node_index = i[j];\n",
    "        node_id = list_of_nodes[node_index];\n",
    "        page_rank_score = π̂[node_index];\n",
    "        label = nodes[node_id].label;\n",
    "        community = nodes[node_id].community;\n",
    "        type = nodes[node_id].type;\n",
    "        push!(df, (Rank = j, NodeID = node_id, PageName = label, Community = community, Type = type, PageRankScore = page_rank_score));\n",
    "    end\n",
    "    \n",
    "    # make the table -\n",
    "    pretty_table(\n",
    "        df;\n",
    "        backend = :text,\n",
    "        fit_table_in_display_horizontally = false,\n",
    "        table_format = TextTableFormat(borders = text_table_borders__compact)\n",
    "    );\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a9598",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c001b0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "The largest eigenpair of a transition matrix reveals the long-term behavior of random walks on graphs, with the stationary distribution representing the steady-state probabilities of visiting each node.\n",
    "\n",
    "> __Key Takeaways:__\n",
    "> \n",
    "> * **Transition matrices encode random walk dynamics:** Normalizing an adjacency matrix produces a stochastic matrix where each row represents transition probabilities from one node to its neighbors.\n",
    "> * **The dominant eigenvector represents steady-state importance:** The eigenvector corresponding to eigenvalue $\\lambda = 1$ gives the stationary distribution, which in the PageRank context measures webpage importance based on link structure.\n",
    "> * **Power iteration efficiently finds the largest eigenpair:** The power iteration algorithm converges to the dominant eigenvector by repeatedly applying the transition matrix, with convergence measured using the $\\ell_{1}$-norm.\n",
    "\n",
    "\n",
    "This mathematical framework provides the foundation for ranking algorithms that assess importance in networked systems.___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc9ace",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb22d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.4",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
